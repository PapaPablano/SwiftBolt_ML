""# SwiftBolt_ML Quick Reference

**Updated**: January 21, 2026  
**Status**: Ready to execute  
**Timeline**: 3 weeks total effort

---

## ğŸ¯ Key Issues At a Glance

| Issue | Severity | Impact | Fix Time | Status |
|-------|----------|--------|----------|--------|
| Symbols table empty | ğŸš« BLOCKING | Swift app returns 0 jobs | 1 hour | READY |
| Dashboard shows 4 conflicting signals | âš ï¸ HIGH | User confusion, poor trades | 3 days | READY |
| 35+ backend scripts (no clarity) | ğŸ’¼ MEDIUM | High maintenance, duplication | 2 days | READY |
| 31 workflows (23 legacy) | ğŸ’¼ MEDIUM | Cluttered CI/CD, potential duplicates | 1 day | READY |
| Options disconnected from forecasts | ğŸ”´ IMPORTANT | Missing signal synthesis | 2 weeks | NEXT PHASE |

---

## ğŸ“Š Quick Wins (This Week)

### Monday (1 hour)

**Fix Swift App Symbol Tracking**

```bash
cd ~/SwiftBolt_ML
psql $DATABASE_URL < backend/scripts/seed-symbols.sql
./backend/scripts/test_symbol_sync.sh
# Result: Swift app unblocked, can add symbols
```

âœ… Effort: 1 hour  
âœ… Value: Unblocks entire Swift app feature

---

### Tuesday-Wednesday (2-3 days)

**Create Unified Validator**

```bash
cd ml
touch src/validation/unified_framework.py
# Copy code from SwiftBolt_Implementation.md
python -m pytest tests/test_unified_validator.py -v
```

âœ… Effort: 2-3 days  
âœ… Value: Dashboard shows single confidence score, not 4 conflicting ones

---

### Thursday-Friday (2 days)

**Consolidate Scripts & Workflows**

```bash
# Archive 30+ legacy scripts
mkdir -p backend/scripts/legacy
mv backend/scripts/*.sh backend/scripts/legacy/
cp backend/scripts/canonical/backfill.sh

# Archive 23 legacy workflows
mkdir -p .github/workflows/legacy
mv .github/workflows/backfill*.yml .github/workflows/legacy/
mv .github/workflows/intraday-update*.yml .github/workflows/legacy/
mv .github/workflows/ml-forecast.yml .github/workflows/legacy/
```

âœ… Effort: 2 days  
âœ… Value: Reduced maintenance burden, clear canonical versions

---

## ğŸ”„ Current vs Recommended Data Architecture

### Current (Fragmented)

```
Market Data
  â”‚
  â”œâ”€â†’ Intraday Job (every 15 min) â†’ M15, H1
  â”‚
  â”œâ”€â†’ Daily Job (6 AM UTC) â†’ M15/H1/H4/D1/W1
  â”‚
  â””â”€â†’ Options Scrape (separate) â†’ Finnhub data

Forecast Pipeline (separate)
  â”‚
  â”œâ”€â†’ ARIMA-GARCH
  â”œâ”€â†’ XGBoost
  â””â”€â†’ Transformer

Validation (3 sources, not reconciled)
  â”‚
  â”œâ”€â†’ Backtesting: 98.8% (historical)
  â”œâ”€â†’ Walk-forward: 78% (quarterly)
  â””â”€â†’ Live: 40% (today - DEGRADED)

Problem: Options not aware of forecasts
         Forecasts not aware of options
         User sees conflicting signals
```

### Recommended (Integrated)

```
Daily ML Orchestration (6 AM UTC)
  â”‚
  â”œâ”€â†’ Stage 1: Data Prep (6:05)
  â”‚   â”œâ”€ Load M15/H1/H4/D1/W1
  â”‚   â”œâ”€ Load options data
  â”‚   â””â”€ Feature engineering
  â”‚
  â”œâ”€â†’ Stage 2: Forecast (6:15)
  â”‚   â”œâ”€ ARIMA-GARCH
  â”‚   â”œâ”€ XGBoost
  â”‚   â””â”€ Ensemble
  â”‚
  â”œâ”€â†’ Stage 3: Options Integration (6:25)
  â”‚   â”œâ”€ Load equity forecast
  â”‚   â”œâ”€ Filter options by Greeks/IV
  â”‚   â””â”€ Rank by risk/reward
  â”‚
  â”œâ”€â†’ Stage 4: Unified Validation (6:35)
  â”‚   â”œâ”€ Backtesting score (40% weight)
  â”‚   â”œâ”€ Walk-forward score (35% weight)
  â”‚   â”œâ”€ Live score (25% weight)
  â”‚   â””â”€ Unified confidence = 76.8%
  â”‚
  â””â”€â†’ Stage 5: Health Check (6:45)
      â”œâ”€ Data freshness
      â”œâ”€ Model performance vs targets
      â””â”€ Slack alerts

Single Dashboard (one source of truth)
  â”‚
  â”œâ”€â†’ Prediction: "Bullish 76.8% confidence"
  â”œâ”€â†’ Why: "Drift detected (-50% from historical)"
  â”œâ”€â†’ Multi-TF: "D1 bullish, M15 bearish (weighted consensus bullish)"
  â””â”€â†’ Options: "Best calls: 40 delta, 65th percentile IV"

Benefit: Options integrated âœ“  
          Forecasts aware of options âœ“  
          User gets coherent signal âœ“
```

---

## ğŸ“‹ Workflow Consolidation Status

### Keep (8 Canonical Workflows)

```
âœ… daily-data-refresh.yml          - OHLC ingestion (keep)
âœ… intraday-ingestion.yml          - Real-time M15/H1 (keep)
âœ… intraday-forecast.yml           - Intraday predictions (keep)
âœ… ml-orchestration.yml            - Full ML suite (keep)
âœ… deploy-supabase.yml             - Edge functions (keep)
âœ… deploy-ml-dashboard.yml         - Dashboard deployment (keep)
âœ… test-ml.yml                     - Unit tests (keep)
âœ… api-contract-tests.yml          - Integration tests (keep)
```

### Archive (23 Workflows to Consolidate)

```
âš ï¸  Backfill Duplicates (4)
    backfill-ohlc.yml â†’ daily-data-refresh
    batch-backfill-cron.yml â†’ daily-data-refresh
    daily-historical-sync.yml â†’ daily-data-refresh
    symbol-backfill.yml â†’ daily-data-refresh

âš ï¸  Intraday Duplicates (5)
    alpaca-intraday-cron.yml â†’ intraday-ingestion
    alpaca-intraday-cron-fixed.yml â†’ intraday-ingestion
    intraday-update.yml â†’ intraday-ingestion
    intraday-update-v2.yml â†’ intraday-ingestion
    backfill-intraday-worker.yml â†’ intraday-ingestion

âš ï¸  ML Pipeline Duplicates (5)
    ml-forecast.yml â†’ ml-orchestration
    ml-evaluation.yml â†’ ml-orchestration
    data-quality-monitor.yml â†’ ml-orchestration
    drift-monitoring.yml â†’ ml-orchestration
    options-nightly.yml â†’ ml-orchestration

â“ Unclear/Dead (9)
    daily-options-scrape.yml â†’ Verify + consolidate into ml-orchestration
    job-worker.yml â†’ Verify + consolidate
    orchestrator-cron.yml â†’ Supabase-specific, keep or consolidate
    symbol-weight-training.yml â†’ Move to ml-orchestration
    sync-user-symbols.yml â†’ No recent runs (likely dead)
    scheduled-refresh.yml â†’ No recent runs (likely dead)
    performance-tracking.yml â†’ 60 days no runs (dead)
    nightly-coverage-check.yml â†’ Keep (separate concern)
    frontend-integration-checks.yml â†’ Keep (separate concern)
```

---

## ğŸ“š Backend Script Status

### Canonical Scripts (Authoritative)

```
âœ… scripts/canonical/backfill.sh     - Backfill OHLC data
âœ… scripts/canonical/deploy.sh       - Deploy all services
âœ… scripts/canonical/validate.sh     - Validate data quality
âœ… scripts/canonical/seed.sh         - Seed initial data
```

### To Archive (30+ Scripts)

```
âš ï¸  Backfill scripts (3-4 versions)
âš ï¸  Diagnostic scripts (6: check_*.sql, diagnose_*.sql)
âš ï¸  Deployment variants (4: deploy_prod.sh, etc.)
âš ï¸  Validation variants (5: validate_*.sh)
âš ï¸  One-off debug scripts (10+)
```

**Action**: Archive to `scripts/legacy/` with README

### Shared Library (New)

```typescript
backend/lib/shared.ts
  â”œâ”€ Database connection utilities
  â”œâ”€ Retry with exponential backoff
  â”œâ”€ Logging (consistent format)
  â”œâ”€ Batch operations
  â””â”€ Error handling

// Usage in scripts:
import { retryWithBackoff, log, batchInsert } from '../lib/shared';
```

---

## ğŸ“ˆ Dashboard Reconciliation Formula

### Current Dashboard Problem

```
User sees:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Statistical Tab: 98.8% âœ… â”‚
â”‚ Live Forecast: 40% â†“     â”‚
â”‚ M15: -48%â†“  H1: -40%â†“    â”‚
â”‚                          â”‚
â”‚ â“ Which one do I trade on?â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Solution: Unified Confidence Score

```
Formula:
Unified = (40% Ã— Backtesting) + (35% Ã— Walk-Forward) + (25% Ã— Live)
        = (40% Ã— 0.988) + (35% Ã— 0.78) + (25% Ã— 0.40)
        = 0.395 + 0.273 + 0.100
        = 0.768 = 76.8%

Dashboard shows:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Confidence: 76.8% âš ï¸          â”‚
â”‚                              â”‚
â”‚ Why it's not higher:         â”‚
â”‚ â€¢ Live accuracy down 50%    â”‚
â”‚ â€¢ Drift detected            â”‚
â”‚ â€¢ Monitor for retraining   â”‚
â”‚                              â”‚
â”‚ Components:                 â”‚
â”‚ â€¢ Historical: 98.8% âœ…      â”‚
â”‚ â€¢ Quarterly: 78% âš ï¸        â”‚
â”‚ â€¢ Recent: 40% âœ—             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Multi-Timeframe Reconciliation

```
When predictions conflict:
M15: BEARISH (-48%)
H1:  BEARISH (-40%)
D1:  BULLISH (+60%)  â† Conflict!
W1:  BULLISH (+70%)

Hierarchy weighting:
W1: 50% weight Ã— BULLISH
D1: 40% weight Ã— BULLISH  
H4: 30% weight Ã— ... (if present)
H1: 20% weight Ã— BEARISH
M15: 10% weight Ã— BEARISH

Consensus: Weighted average = Consensus Direction
           + Confidence penalty for conflict

Dashboard shows:
"Consensus: BULLISH (but watch M15 for pullback)"
```

---

## âœ… Success Criteria Checklist

### By End of Week 1

**Monday (Done)**
- [ ] Symbols table has 8 core symbols
- [ ] test_symbol_sync.sh returns "jobs_created: 3"
- [ ] Swift app can add symbols without errors

**Tuesday-Wednesday (Done)**
- [ ] unified_framework.py created and tested
- [ ] All unit tests passing (test_unified_validator.py)
- [ ] Integration into ml_orchestration.yml working
- [ ] Sample predictions stored with unified score

**Thursday-Friday (Done)**
- [ ] 4 canonical scripts in scripts/canonical/
- [ ] 30+ old scripts archived to scripts/legacy/
- [ ] 8 canonical workflows remaining in .github/workflows/
- [ ] 23 legacy workflows in .github/workflows/legacy/
- [ ] README files documenting consolidation

### By End of Week 2

- [ ] Dashboard shows unified confidence score
- [ ] Drift alerts visible on dashboard
- [ ] Multi-TF reconciliation displayed
- [ ] User testing completed
- [ ] Deployed to production

### By End of Week 3

- [ ] Options integrated into forecasts
- [ ] Auto-create symbols on demand
- [ ] Real-time performance tracking
- [ ] Model retraining on drift detection

---

## ğŸ“Š Effort Estimate

| Task | Duration | Effort | Value | Priority |
|------|----------|--------|-------|----------|
| Fix symbols table | 1h | ğŸ‘¨ | ğŸ‘¨ğŸ‘¨ğŸ‘¨ | NOW |
| Unified validator | 3d | ğŸ‘¨ğŸ‘¨ | ğŸ‘¨ğŸ‘¨ğŸ‘¨ | THIS WEEK |
| Consolidate scripts | 2d | ğŸ‘¨ğŸ‘¨ | ğŸ‘¨ğŸ‘¨ | THIS WEEK |
| Consolidate workflows | 1d | ğŸ‘¨ | ğŸ‘¨ğŸ‘¨ | THIS WEEK |
| Dashboard redesign | 1w | ğŸ‘¨ğŸ‘¨ğŸ‘¨ | ğŸ‘¨ğŸ‘¨ğŸ‘¨ | NEXT WEEK |
| Options integration | 2w | ğŸ‘¨ğŸ‘¨ğŸ‘¨ | ğŸ‘¨ğŸ‘¨ğŸ‘¨ | MONTH 2 |
| **TOTAL** | **3 weeks** | | |

---

## ğŸš€ Getting Started Tomorrow

### 8:00 AM Monday

```bash
# 1-hour fix
cd ~/SwiftBolt_ML

# Seed symbols
psql $DATABASE_URL < backend/scripts/seed-symbols.sql

# Verify
psql $DATABASE_URL -c "SELECT COUNT(*) FROM symbols;"
# Expected: 8

# Test end-to-end
./backend/scripts/test_symbol_sync.sh
# Expected: jobs_created: 3

# Redeploy Swift app
echo "ğŸš€ Swift app now ready to use"
```

### 9:00 AM Tuesday

```bash
# Start unified validator
cd ml
touch src/validation/unified_framework.py
# Copy code from SwiftBolt_Implementation.md

# Run tests
python -m pytest tests/test_unified_validator.py -v
```

---

## ğŸ—‚ï¸ Key Files to Know

### New Files to Create

- `ml/src/validation/unified_framework.py` - Validator logic
- `ml/tests/test_unified_validator.py` - Validator tests
- `ml/src/models/unified_output.py` - Store predictions
- `backend/lib/shared.ts` - Shared utilities
- `backend/scripts/canonical/backfill.sh` - Canonical backfill
- `backend/scripts/canonical/deploy.sh` - Canonical deploy
- `backend/scripts/canonical/validate.sh` - Canonical validate
- `backend/scripts/canonical/seed.sh` - Canonical seed

### Existing Files to Update

- `.github/workflows/ml-orchestration.yml` - Add validation stage
- `.github/workflows/daily-data-refresh.yml` - Use shared lib
- `backend/scripts/seed-symbols.sql` - Populate with core symbols
- `backend/scripts/test_symbol_sync.sh` - Test harness

### Files to Archive

- `backend/scripts/*.sh` (old versions) â†’ `backend/scripts/legacy/`
- `.github/workflows/backfill*.yml` â†’ `.github/workflows/legacy/`
- `.github/workflows/intraday-update*.yml` â†’ `.github/workflows/legacy/`
- `.github/workflows/ml-forecast.yml` â†’ `.github/workflows/legacy/`

---

## ğŸ¤” Questions to Answer

**Before you start, decide:**

1. **Validation Weights**: Should backtesting be 40% (current)? Or increase live to 40%?
2. **Drift Threshold**: Is 25% divergence the right threshold? Or 15%?
3. **Retraining Frequency**: On schedule (30 days)? On drift detection? Manual only?
4. **Timeframe Hierarchy**: D1 > H4 > H1 > M15? Or by recent performance?
5. **Options Integration**: Should IV skew adjust model confidence?
6. **Auto-Create Symbols**: From Finnhub on demand? Or manual only?

Document decisions in: `ml/docs/VALIDATION_FRAMEWORK.md`

---

## ğŸ“– Reference Documents

1. **This document** - Quick overview (start here)
2. `SwiftBolt_System_Audit.md` - Deep technical analysis
3. `SwiftBolt_Implementation.md` - Step-by-step code examples
4. `ml/docs/VALIDATION_FRAMEWORK.md` - Validation rules (create this)
5. `backend/scripts/legacy/README.md` - Archive guide (create this)
6. `.github/workflows/legacy/README.md` - Workflow guide (create this)

---

## â­ The Insight

Your system is **architecturally excellent**. The issue isn't the designâ€”it's **accumulation and fragmentation**.

You have:
- âœ… Great data ingestion (Alpaca, Finnhub)
- âœ… Great ML models (ensemble approach)
- âœ… Great app integration (Swift + Supabase)

But you're showing users **4 conflicting signals** instead of 1 coherent signal.

**The fix**: Add an explicit reconciliation layer that combines backtesting, walk-forward, and live scores with clear rules and context.

This is high-value work because it directly improves:
- ğŸ“ˆ Trading signal quality
- ğŸ¤ User trust in model
- âš™ï¸ System maintainability

**Ready?** Start with the symbols table tomorrow morning. 1 hour. Changes everything.
""