# Live Predictions Population Fix
**Date**: January 23, 2026  
**Issue**: `live_predictions` table empty, causing default scores in unified validation  
**Status**: âœ… **Fixed**

---

## ðŸ” Problem Identified

The `live_predictions` table was empty, causing the `ValidationService` to use default scores (0.50, 0.55, 0.60) instead of real accuracy scores.

### Root Cause

1. **Forecasts are written to `ml_forecasts`** âœ…
   - The `ml-forecast` job writes forecasts to `ml_forecasts` table
   - This is working correctly

2. **Evaluations are written to `forecast_evaluations`** âœ…
   - The `evaluation_job` evaluates forecasts and writes to `forecast_evaluations`
   - This is working correctly

3. **Missing link: `live_predictions` not populated** âŒ
   - The `live_predictions` table is designed to store per-timeframe predictions with accuracy scores
   - But there was no code that:
     - Reads from `forecast_evaluations`
     - Calculates accuracy scores per symbol/timeframe
     - Writes to `live_predictions`

### Why This Matters

The `ValidationService._get_live_score()` method reads from `live_predictions`:
- If empty â†’ returns default 0.50
- If populated â†’ returns real accuracy scores

Without `live_predictions` populated, unified validation always uses default scores.

---

## âœ… Solution

### Created `populate_live_predictions.py` Script

**Location**: `ml/src/scripts/populate_live_predictions.py`

**What it does**:
1. Reads recent `forecast_evaluations` (last 30 days by default)
2. Groups by symbol + horizon
3. Calculates accuracy scores (correct / total)
4. Maps horizons to timeframes (1D â†’ d1, 1W â†’ w1, etc.)
5. Writes to `live_predictions` table with:
   - `symbol_id`
   - `timeframe` (m15, h1, h4, d1, w1)
   - `signal` (BULLISH, BEARISH, NEUTRAL)
   - `accuracy_score` (0-1)
   - `metadata` (evaluation counts, dates)

### Added to ML Orchestration Workflow

**File**: `.github/workflows/ml-orchestration.yml`

**New Step**: "Populate live_predictions from evaluations"
- Runs after `evaluation_job`
- Runs before `unified validation`
- Ensures `live_predictions` is populated with latest accuracy scores

---

## ðŸ“Š How It Works

### Data Flow

```
1. ml-forecast job
   â””â”€> Writes forecasts to ml_forecasts âœ…

2. evaluation_job
   â””â”€> Evaluates forecasts against actual prices
   â””â”€> Writes to forecast_evaluations âœ…

3. populate_live_predictions (NEW)
   â””â”€> Reads from forecast_evaluations
   â””â”€> Calculates accuracy per symbol/timeframe
   â””â”€> Writes to live_predictions âœ…

4. unified validation
   â””â”€> Reads from live_predictions
   â””â”€> Uses real accuracy scores âœ…
```

### Horizon to Timeframe Mapping

| Horizon | Timeframe | Description |
|---------|-----------|-------------|
| 1D | d1 | Daily |
| 1W | w1 | Weekly |
| 1M | m1 | Monthly |
| 15m | m15 | 15-minute (intraday) |
| 1h | h1 | 1-hour (intraday) |
| 4h | h4 | 4-hour (intraday) |

### Accuracy Calculation

For each symbol + horizon:
- **Total evaluations**: Count of evaluations in last 30 days
- **Correct evaluations**: Count where `direction_correct = true`
- **Accuracy score**: `correct / total`

**Minimum threshold**: At least 3 evaluations required to write a prediction (ensures meaningful accuracy)

---

## ðŸ”§ Usage

### Manual Run

```bash
cd ml
python -m src.scripts.populate_live_predictions --days-back 30
```

### Automatic Run

Runs automatically in `ml-orchestration` workflow after evaluation job.

---

## âœ… Expected Behavior

### Before Fix

```
Insufficient live data for AAPL (got 0 predictions)
ðŸŸ  AAPL: 47.2% confidence
   â„¹ï¸  Using default scores (live_predictions table empty)
```

### After Fix (Once Evaluations Exist)

```
ðŸŸ¢ AAPL: 62.3% confidence
   Drift: none (9%)
   Consensus: BULLISH
   Live score: 0.65 (from live_predictions)
```

---

## ðŸ“‹ Requirements

### For `live_predictions` to be populated:

1. **Forecasts must exist** âœ…
   - `ml_forecasts` table has forecasts
   - Generated by `ml-forecast` job

2. **Evaluations must exist** âœ…
   - `forecast_evaluations` table has evaluations
   - Generated by `evaluation_job`
   - Need at least 3 evaluations per symbol/horizon

3. **Time must pass** â°
   - Forecasts need time to be evaluated (e.g., 1D forecasts evaluated after 1 day)
   - First run may have no evaluations yet

### Timeline Example

**Day 1**: 
- `ml-forecast` runs â†’ writes forecasts to `ml_forecasts`
- `evaluation_job` runs â†’ no evaluations yet (forecasts too new)
- `populate_live_predictions` runs â†’ no data to populate

**Day 2**:
- `evaluation_job` runs â†’ evaluates Day 1 forecasts â†’ writes to `forecast_evaluations`
- `populate_live_predictions` runs â†’ reads evaluations â†’ writes to `live_predictions`
- `unified validation` runs â†’ reads from `live_predictions` â†’ uses real scores âœ…

---

## ðŸŽ¯ Result

### Current Status

- âœ… Script created and added to workflow
- âœ… Will populate `live_predictions` after evaluations exist
- â° First run may still show defaults (no evaluations yet)

### Next Steps

1. **Run ML Orchestration workflow** to generate forecasts
2. **Wait for evaluations** (forecasts need time to be evaluated)
3. **Re-run workflow** â†’ `live_predictions` will be populated
4. **Unified validation** will use real scores

---

## ðŸ“Š Verification

### Check if `live_predictions` is populated:

```sql
SELECT 
  s.ticker,
  lp.timeframe,
  lp.signal,
  lp.accuracy_score,
  lp.prediction_time
FROM live_predictions lp
JOIN symbols s ON s.id = lp.symbol_id
ORDER BY lp.prediction_time DESC
LIMIT 10;
```

### Check evaluation count:

```sql
SELECT 
  symbol,
  horizon,
  COUNT(*) as eval_count,
  SUM(CASE WHEN direction_correct THEN 1 ELSE 0 END) as correct_count
FROM forecast_evaluations
WHERE evaluation_date >= NOW() - INTERVAL '30 days'
GROUP BY symbol, horizon
ORDER BY eval_count DESC;
```

---

## âœ… Summary

**Problem**: `live_predictions` table empty â†’ default scores used  
**Solution**: Created script to populate `live_predictions` from `forecast_evaluations`  
**Status**: âœ… **Fixed** - Script created and added to workflow

**Note**: First run may still show defaults until evaluations accumulate (this is expected).

---

**Status**: âœ… **Fixed**  
**Files Created**:
- `ml/src/scripts/populate_live_predictions.py`

**Files Modified**:
- `.github/workflows/ml-orchestration.yml`

**Last Updated**: January 23, 2026
