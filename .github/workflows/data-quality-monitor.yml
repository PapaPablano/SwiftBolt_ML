name: Data Quality Monitor

# Monitors data quality across all timeframes and alerts on staleness
# Runs after each data refresh to ensure quality standards are met
# Includes checks for: OHLC bars, options snapshots, and forecast freshness

on:
  schedule:
    # Run every 6 hours to check data quality
    - cron: '0 */6 * * *'
  workflow_dispatch:
    inputs:
      symbols:
        description: 'Symbols to check (comma-separated)'
        required: false
        type: string
        default: 'AAPL,MSFT,NVDA,TSLA,META'
      check_options:
        description: 'Check options snapshot recency'
        required: false
        type: boolean
        default: true
      check_forecasts:
        description: 'Check forecast staleness'
        required: false
        type: boolean
        default: true
      
permissions:
  contents: read
  issues: write

concurrency:
  group: data-quality-monitor-${{ github.ref }}
  cancel-in-progress: true

env:
  # Staleness thresholds in hours
  OPTIONS_STALE_HOURS: 6
  FORECAST_STALE_HOURS: 24

jobs:
  validate-data:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    outputs:
      bars_status: ${{ steps.validate.outputs.status }}
      options_status: ${{ steps.options_check.outputs.status }}
      forecast_status: ${{ steps.forecast_check.outputs.status }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup environment
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        run: |
          # Create .env for validation script
          cat > .env << EOF
          DATABASE_URL=${DATABASE_URL}
          SUPABASE_URL=${SUPABASE_URL}
          SUPABASE_KEY=${SUPABASE_KEY}
          EOF
      
      - name: Install PostgreSQL client
        run: |
          sudo apt-get update
          sudo apt-get install -y postgresql-client
      
      - name: Run data quality validation
        id: validate
        run: |
          SYMBOLS="${{ github.event.inputs.symbols || 'AAPL,MSFT,NVDA,TSLA,META' }}"
          
          echo "## Data Quality Report - $(date)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Run validation script
          chmod +x scripts/validate_data_quality.sh
          if ./scripts/validate_data_quality.sh "$SYMBOLS" > /tmp/report.txt 2>&1; then
            echo "status=success" >> $GITHUB_OUTPUT
            echo "✅ OHLC Bars validation PASSED" >> $GITHUB_STEP_SUMMARY
          else
            echo "status=failure" >> $GITHUB_OUTPUT
            echo "❌ OHLC Bars validation FAILED" >> $GITHUB_STEP_SUMMARY
          fi
          
          # Add report to summary
          echo "" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          cat /tmp/report.txt >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY

      - name: Check options snapshot recency
        id: options_check
        if: ${{ github.event.inputs.check_options != 'false' }}
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
        run: |
          SYMBOLS="${{ github.event.inputs.symbols || 'AAPL,MSFT,NVDA,TSLA,META' }}"
          SYMBOL_LIST=$(echo $SYMBOLS | sed "s/,/','/g")
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Options Snapshot Recency" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Query options snapshot freshness
          SQL_QUERY="
          SELECT 
            s.ticker,
            MAX(os.snapshot_at) as latest_snapshot,
            EXTRACT(EPOCH FROM (NOW() - MAX(os.snapshot_at))) / 3600 as age_hours,
            COUNT(*) as snapshot_count
          FROM options_snapshots os
          JOIN symbols s ON s.ticker = os.underlying_symbol
          WHERE s.ticker IN ('$SYMBOL_LIST')
          GROUP BY s.ticker
          ORDER BY age_hours DESC;
          "
          
          RESULT=$(psql "$DATABASE_URL" -t -c "$SQL_QUERY" 2>/dev/null || echo "")
          
          if [ -z "$RESULT" ]; then
            echo "⚠️ No options snapshots found" >> $GITHUB_STEP_SUMMARY
            echo "status=warning" >> $GITHUB_OUTPUT
          else
            echo "| Symbol | Latest Snapshot | Age (hours) | Status |" >> $GITHUB_STEP_SUMMARY
            echo "|--------|-----------------|-------------|--------|" >> $GITHUB_STEP_SUMMARY
            
            stale_count=0
            while IFS='|' read -r ticker latest age count; do
              ticker=$(echo "$ticker" | xargs)
              latest=$(echo "$latest" | xargs)
              age=$(echo "$age" | xargs)
              
              [ -z "$ticker" ] && continue
              
              age_int=${age%.*}
              if [ "$age_int" -gt "$OPTIONS_STALE_HOURS" ]; then
                echo "| $ticker | $latest | $age | ❌ STALE |" >> $GITHUB_STEP_SUMMARY
                stale_count=$((stale_count + 1))
              else
                echo "| $ticker | $latest | $age | ✅ OK |" >> $GITHUB_STEP_SUMMARY
              fi
            done <<< "$RESULT"
            
            if [ "$stale_count" -gt 0 ]; then
              echo "status=failure" >> $GITHUB_OUTPUT
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "⚠️ $stale_count symbols have stale options data (> $OPTIONS_STALE_HOURS hours)" >> $GITHUB_STEP_SUMMARY
            else
              echo "status=success" >> $GITHUB_OUTPUT
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "✅ All options snapshots are fresh" >> $GITHUB_STEP_SUMMARY
            fi
          fi

      - name: Check forecast staleness
        id: forecast_check
        if: ${{ github.event.inputs.check_forecasts != 'false' }}
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
        run: |
          SYMBOLS="${{ github.event.inputs.symbols || 'AAPL,MSFT,NVDA,TSLA,META' }}"
          SYMBOL_LIST=$(echo $SYMBOLS | sed "s/,/','/g")
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Forecast Staleness" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Query forecast freshness
          SQL_QUERY="
          SELECT 
            s.ticker,
            mf.horizon,
            mf.run_at as latest_forecast,
            EXTRACT(EPOCH FROM (NOW() - mf.run_at)) / 3600 as age_hours,
            mf.overall_label,
            mf.confidence
          FROM ml_forecasts mf
          JOIN symbols s ON s.id = mf.symbol_id
          WHERE s.ticker IN ('$SYMBOL_LIST')
            AND mf.run_at = (
              SELECT MAX(run_at) FROM ml_forecasts mf2 
              WHERE mf2.symbol_id = mf.symbol_id AND mf2.horizon = mf.horizon
            )
          ORDER BY age_hours DESC;
          "
          
          RESULT=$(psql "$DATABASE_URL" -t -c "$SQL_QUERY" 2>/dev/null || echo "")
          
          if [ -z "$RESULT" ]; then
            echo "⚠️ No forecasts found" >> $GITHUB_STEP_SUMMARY
            echo "status=warning" >> $GITHUB_OUTPUT
          else
            echo "| Symbol | Horizon | Latest Run | Age (hours) | Label | Status |" >> $GITHUB_STEP_SUMMARY
            echo "|--------|---------|------------|-------------|-------|--------|" >> $GITHUB_STEP_SUMMARY
            
            stale_count=0
            while IFS='|' read -r ticker horizon latest age label confidence; do
              ticker=$(echo "$ticker" | xargs)
              horizon=$(echo "$horizon" | xargs)
              latest=$(echo "$latest" | xargs)
              age=$(echo "$age" | xargs)
              label=$(echo "$label" | xargs)
              
              [ -z "$ticker" ] && continue
              
              age_int=${age%.*}
              if [ "$age_int" -gt "$FORECAST_STALE_HOURS" ]; then
                echo "| $ticker | $horizon | $latest | $age | $label | ❌ STALE |" >> $GITHUB_STEP_SUMMARY
                stale_count=$((stale_count + 1))
              else
                echo "| $ticker | $horizon | $latest | $age | $label | ✅ OK |" >> $GITHUB_STEP_SUMMARY
              fi
            done <<< "$RESULT"
            
            if [ "$stale_count" -gt 0 ]; then
              echo "status=failure" >> $GITHUB_OUTPUT
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "⚠️ $stale_count forecasts are stale (> $FORECAST_STALE_HOURS hours)" >> $GITHUB_STEP_SUMMARY
            else
              echo "status=success" >> $GITHUB_OUTPUT
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "✅ All forecasts are fresh" >> $GITHUB_STEP_SUMMARY
            fi
          fi
      
      - name: Check for stale data
        if: steps.validate.outputs.status == 'failure' || steps.options_check.outputs.status == 'failure' || steps.forecast_check.outputs.status == 'failure'
        run: |
          echo "::warning::Data quality issues detected. Check the report for details."
          echo "Consider running the comprehensive backfill workflow to fix data gaps."
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "### Remediation Steps" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **OHLC Bars:** Run \`gh workflow run daily-data-refresh.yml --field force_full_backfill=true\`" >> $GITHUB_STEP_SUMMARY
          echo "- **Options:** Run \`gh workflow run daily-options-scrape.yml\`" >> $GITHUB_STEP_SUMMARY
          echo "- **Forecasts:** Run \`gh workflow run ml-forecast.yml\`" >> $GITHUB_STEP_SUMMARY
      
      - name: Upload validation report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: data-quality-report-${{ github.run_number }}
          path: /tmp/report.txt
          retention-days: 14
      
      - name: Create issue on repeated failures
        if: steps.validate.outputs.status == 'failure' || steps.options_check.outputs.status == 'failure' || steps.forecast_check.outputs.status == 'failure'
        uses: actions/github-script@v7
        with:
          script: |
            // Ensure required labels exist (GitHub API errors if you assign non-existent labels)
            const requiredLabels = [
              { name: 'data-quality', color: 'd93f0b', description: 'Automated data quality monitoring' },
              { name: 'automated', color: '0e8a16', description: 'Created automatically by GitHub Actions' },
            ];

            for (const label of requiredLabels) {
              try {
                await github.rest.issues.getLabel({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  name: label.name,
                });
              } catch (err) {
                if (err?.status === 404) {
                  await github.rest.issues.createLabel({
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    name: label.name,
                    color: label.color,
                    description: label.description,
                  });
                } else {
                  throw err;
                }
              }
            }

            // Determine which checks failed
            const barsStatus = '${{ steps.validate.outputs.status }}';
            const optionsStatus = '${{ steps.options_check.outputs.status }}';
            const forecastStatus = '${{ steps.forecast_check.outputs.status }}';
            
            const failures = [];
            if (barsStatus === 'failure') failures.push('OHLC Bars');
            if (optionsStatus === 'failure') failures.push('Options Snapshots');
            if (forecastStatus === 'failure') failures.push('ML Forecasts');

            // Check if there's already an open issue about data quality
            const issues = await github.rest.issues.listForRepo({
              owner: context.repo.owner,
              repo: context.repo.repo,
              state: 'open',
              labels: 'data-quality'
            });
            
            if (issues.data.length === 0) {
              // Create new issue
              await github.rest.issues.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title: `Data Quality Issues Detected: ${failures.join(', ')}`,
                body: [
                  '## Data Quality Validation Failed',
                  '',
                  'The automated data quality check has detected issues with:',
                  failures.map(f => `- **${f}**`).join('\n'),
                  '',
                  '**Workflow Run:** ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}',
                  '',
                  '### Recommended Actions',
                  '',
                  '#### For OHLC Bars:',
                  '```bash',
                  'gh workflow run daily-data-refresh.yml --field force_full_backfill=true',
                  '```',
                  '',
                  '#### For Options Snapshots:',
                  '```bash',
                  'gh workflow run daily-options-scrape.yml',
                  '```',
                  '',
                  '#### For ML Forecasts:',
                  '```bash',
                  'gh workflow run ml-forecast.yml',
                  '```',
                  '',
                  '### Investigation Steps',
                  '',
                  '1. Review the validation report artifact attached to the workflow run',
                  '2. Check if scheduled GitHub Actions workflows are running on time',
                  '3. Verify API credentials (Alpaca, Supabase) are valid',
                  '4. Check for rate limiting issues in workflow logs',
                  '5. Review database connectivity and storage limits',
                  '',
                  'This issue will auto-close when data quality validation passes.',
                ].join('\n'),
                labels: ['data-quality', 'automated']
              });
              
              core.notice('Created new data quality issue');
            } else {
              core.notice('Data quality issue already exists');
            }

