name: Alpaca Intraday Update (Market Hours)

# =============================================================================
# LEGACY WORKFLOW - TO BE CONSOLIDATED
# =============================================================================
# This workflow is being consolidated into intraday-ingestion.yml
# For now it remains active but will be deprecated in the next phase.
# See: .github/workflows/intraday-ingestion.yml
# =============================================================================

# Runs every 15 minutes during US market hours to fetch fresh intraday data
# This is the PRIMARY source for real-time chart data in the iOS app

on:
  # RE-ENABLED: Fixed missing rsi_14 column issue
  schedule:
    # Run every 15 minutes during extended market hours (9:00 AM - 5:00 PM ET)
    # Cron is in UTC: ET is UTC-5 (winter) or UTC-4 (DST)
    - cron: '*/15 13-22 * * 1-5'  # Every 15 min, 1PM-10PM UTC, Mon-Fri
  workflow_dispatch:
    inputs:
      symbols:
        description: 'Comma-separated symbols (leave empty for all watchlist)'
        required: false
        type: string
      timeframes:
        description: 'Comma-separated timeframes (default: m15,h1,h4)'
        required: false
        type: string
        default: 'm15,h1,h4'
      force_refresh:
        description: 'Force refresh even if data exists'
        required: false
        type: boolean
        default: false

concurrency:
  group: alpaca-intraday-${{ github.ref }}
  cancel-in-progress: true

jobs:
  check-market:
    runs-on: ubuntu-latest
    outputs:
      should_run: ${{ steps.market.outputs.should_run }}
      market_state: ${{ steps.market.outputs.market_state }}
    steps:
      - name: Check Market Hours
        id: market
        run: |
          # Detect manual dispatch (workflow_dispatch) to allow weekend/after-hours overrides
          manual_override=false
          if [ "${GITHUB_EVENT_NAME}" = "workflow_dispatch" ]; then
            manual_override=true
            echo "Manual dispatch detected - bypassing market-hour gating."
          fi

          # Get current time in ET
          current_hour=$(TZ="America/New_York" date +%H)
          current_min=$(TZ="America/New_York" date +%M)
          day_of_week=$(TZ="America/New_York" date +%u)  # 1=Monday, 7=Sunday

          echo "Current ET time: $current_hour:$current_min (day $day_of_week)"

          manual_market_state=""

          # Skip weekends unless manual override is active
          if [ "$day_of_week" -gt 5 ]; then
            if [ "$manual_override" = "true" ]; then
              echo "Weekend detected but manual override enabled - continuing."
              manual_market_state="manual_weekend"
            else
              echo "Weekend - skipping"
              echo "should_run=false" >> $GITHUB_OUTPUT
              echo "market_state=weekend" >> $GITHUB_OUTPUT
              exit 0
            fi
          fi

          # Check if within extended market hours (9:00 AM - 5:00 PM ET)
          current_minutes=$((current_hour * 60 + current_min))
          pre_market=$((9 * 60))        # 9:00 AM = 540 minutes
          post_market=$((17 * 60))      # 5:00 PM = 1020 minutes
          market_open=$((9 * 60 + 30))  # 9:30 AM = 570 minutes
          market_close=$((16 * 60))     # 4:00 PM = 960 minutes

          if [ "$manual_override" != "true" ]; then
            if [ "$current_minutes" -lt "$pre_market" ] || [ "$current_minutes" -gt "$post_market" ]; then
              echo "Outside extended market hours - skipping"
              echo "should_run=false" >> $GITHUB_OUTPUT
              echo "market_state=closed" >> $GITHUB_OUTPUT
              exit 0
            fi
          fi

          # Determine market state unless already set by manual weekend override
          if [ -z "$manual_market_state" ]; then
            if [ "$current_minutes" -ge "$market_open" ] && [ "$current_minutes" -le "$market_close" ]; then
              echo "market_state=open" >> $GITHUB_OUTPUT
            elif [ "$current_minutes" -lt "$market_open" ]; then
              echo "market_state=pre_market" >> $GITHUB_OUTPUT
            else
              echo "market_state=after_hours" >> $GITHUB_OUTPUT
            fi
          else
            echo "market_state=$manual_market_state" >> $GITHUB_OUTPUT
          fi

          echo "should_run=true" >> $GITHUB_OUTPUT
          echo "time=$current_hour:$current_min ET" >> $GITHUB_OUTPUT

  update-intraday:
    needs: check-market
    if: needs.check-market.outputs.should_run == 'true' || github.event_name == 'workflow_dispatch'
    runs-on: ubuntu-latest
    timeout-minutes: 30
    env:
      SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
      SUPABASE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
      SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
      ALPACA_API_KEY: ${{ secrets.ALPACA_API_KEY }}
      ALPACA_API_SECRET: ${{ secrets.ALPACA_API_SECRET }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: 'ml/requirements.txt'

      - name: Install dependencies
        run: |
          cd ml
          pip install -r requirements.txt

      - name: Configure environment
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL || vars.DATABASE_URL }}
          WEBHOOK_URL: ${{ secrets.WEBHOOK_URL || vars.WEBHOOK_URL }}
        run: |
          if [ -z "$DATABASE_URL" ]; then
            echo "DATABASE_URL is not configured" >&2
            exit 1
          fi

          if [ -n "$WEBHOOK_URL" ]; then
            echo "WEBHOOK_URL configured"
          else
            echo "WEBHOOK_URL not set; webhook step will remain disabled"
          fi

          # Write .env at repository root so Python scripts can locate it
          {
            echo "SUPABASE_URL=${SUPABASE_URL}"
            echo "SUPABASE_KEY=${SUPABASE_KEY}"
            echo "DATABASE_URL=${DATABASE_URL}"
            echo "ALPACA_API_KEY=${ALPACA_API_KEY}"
            echo "ALPACA_API_SECRET=${ALPACA_API_SECRET}"
          } > .env

          # Persist critical env vars for subsequent steps
          echo "SUPABASE_URL=${SUPABASE_URL}" >> "$GITHUB_ENV"
          echo "SUPABASE_KEY=${SUPABASE_KEY}" >> "$GITHUB_ENV"
          echo "SUPABASE_SERVICE_ROLE_KEY=${SUPABASE_SERVICE_ROLE_KEY}" >> "$GITHUB_ENV"
          echo "DATABASE_URL=${DATABASE_URL}" >> "$GITHUB_ENV"
          echo "ALPACA_API_KEY=${ALPACA_API_KEY}" >> "$GITHUB_ENV"
          echo "ALPACA_API_SECRET=${ALPACA_API_SECRET}" >> "$GITHUB_ENV"
          echo "WEBHOOK_URL=${WEBHOOK_URL}" >> "$GITHUB_ENV"

      - name: Fetch intraday data
        id: fetch
        env:
          INPUT_SYMBOLS: ${{ github.event.inputs.symbols }}
          INPUT_TIMEFRAMES: ${{ github.event.inputs.timeframes || 'm15,h1,h4' }}
          FORCE_REFRESH: ${{ github.event.inputs.force_refresh || 'false' }}
          MARKET_STATE: ${{ needs.check-market.outputs.market_state }}
        run: |
          cd ml

          # If market is closed and this isn't a forced refresh, avoid Alpaca calls entirely.
          if [ "$MARKET_STATE" != "open" ] && [ "$FORCE_REFRESH" != "true" ] && [ "$GITHUB_EVENT_NAME" != "workflow_dispatch" ]; then
             echo "Market state is '$MARKET_STATE' and force_refresh is false. Skipping Alpaca backfill."

             python - <<-'PY'
          	import os
          	import sys
          	from pathlib import Path

          	from dotenv import load_dotenv

          	repo_root = Path.cwd().parent
          	load_dotenv(repo_root / ".env")

          	sys.path.insert(0, str(repo_root))

          	from src.data.supabase_db import db

          	def resolve_symbols() -> list[str]:
          	    symbols_input = os.getenv("INPUT_SYMBOLS", "")
          	    symbols = [s.strip().upper() for s in symbols_input.split(",") if s.strip()]
          	    if symbols:
          	        return symbols
          	    try:
          	        from src.scripts.get_watchlist_symbols import get_watchlist_symbols

          	        symbols = get_watchlist_symbols()
          	        if symbols:
          	            return symbols
          	    except Exception as exc:
          	        print(f"Warning: could not fetch watchlist symbols: {exc}")
          	    return ["AAPL", "SPY", "TSLA"]

          	def resolve_timeframes() -> list[str]:
          	    tf_raw = os.getenv("INPUT_TIMEFRAMES", "m15,h1,h4")
          	    return [t.strip() for t in tf_raw.split(",") if t.strip()]

          	symbols = resolve_symbols()
          	timeframes = resolve_timeframes()

          	summary_path = os.environ.get("GITHUB_STEP_SUMMARY")
          	if summary_path:
          	    with open(summary_path, "a", encoding="utf-8") as fh:
          	        fh.write("## Supabase Intraday Snapshot\n")
          	        fh.write("| Symbol | Timeframe | Bars | Latest Timestamp |\n")
          	        fh.write("|--------|-----------|------|------------------|\n")

          	for sym in symbols:
          	    for tf in timeframes:
          	        try:
          	            df = db.fetch_ohlc_bars(sym, timeframe=tf, limit=100)
          	            count = len(df)
          	            latest = df["ts"].max() if not df.empty else None
          	            latest_iso = latest.isoformat() if latest is not None else "n/a"
          	            print(f"{sym}/{tf}: {count} bars (latest={latest_iso})")
          	            if summary_path:
          	                with open(summary_path, "a", encoding="utf-8") as fh:
          	                    fh.write(f"| {sym} | {tf} | {count} | {latest_iso} |\n")
          	        except Exception as exc:
          	            print(f"{sym}/{tf}: error reading Supabase data: {exc}")
          	            if summary_path:
          	                with open(summary_path, "a", encoding="utf-8") as fh:
          	                    fh.write(f"| {sym} | {tf} | error | {exc} |\n")
          	PY

             echo "total_bars=0" >> "$GITHUB_OUTPUT"
             echo "failed_timeframes=" >> "$GITHUB_OUTPUT"
             exit 0
          fi

          # Parse timeframes
          IFS=',' read -ra TIMEFRAMES <<< "$INPUT_TIMEFRAMES"

          echo "## Alpaca Intraday Update" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Timeframe | Status | Bars Updated |" >> $GITHUB_STEP_SUMMARY
          echo "|-----------|--------|--------------|" >> $GITHUB_STEP_SUMMARY

          total_bars=0
          failed_timeframes=""

          for tf in "${TIMEFRAMES[@]}"; do
            tf=$(echo "$tf" | xargs)  # Trim whitespace
            echo "Processing timeframe: $tf"

            # Build command
            cmd="python src/scripts/alpaca_backfill_ohlc_v2.py --timeframe $tf"

            if [ "$FORCE_REFRESH" = "true" ]; then
              cmd="$cmd --force"
            fi

            if [ -n "$INPUT_SYMBOLS" ]; then
              # Split symbols and add to command
              IFS=',' read -ra SYMBOLS <<< "$INPUT_SYMBOLS"
              cmd="$cmd --symbols ${SYMBOLS[*]}"
            else
              cmd="$cmd --all"
            fi

            # Run backfill and capture output
            if output=$($cmd 2>&1); then
              echo "$output" | tail -n 60
              bars=$(echo "$output" | grep -oP 'Inserted \K\d+' | tail -1 || echo "0")
              bars=${bars:-0}
              total_bars=$((total_bars + bars))
              echo "| $tf | ✅ Success | $bars |" >> $GITHUB_STEP_SUMMARY
              echo "✅ $tf: $bars bars"
            else
              echo "| $tf | ❌ Failed | - |" >> $GITHUB_STEP_SUMMARY
              echo "❌ $tf failed: $output"
              failed_timeframes="$failed_timeframes $tf"
            fi
          done

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Total bars updated:** $total_bars" >> $GITHUB_STEP_SUMMARY
          echo "**Market state:** ${{ needs.check-market.outputs.market_state }}" >> $GITHUB_STEP_SUMMARY

          # Set outputs
          echo "total_bars=$total_bars" >> $GITHUB_OUTPUT
          echo "failed_timeframes=$failed_timeframes" >> $GITHUB_OUTPUT

          # Fail if any timeframe failed
          if [ -n "$failed_timeframes" ]; then
            echo "::warning::Some timeframes failed:$failed_timeframes"
          fi

      - name: Generate intraday forecasts
        if: always()
        env:
          INPUT_SYMBOLS: ${{ github.event.inputs.symbols }}
        run: |
          cd ml

          if [ -n "$INPUT_SYMBOLS" ]; then
            IFS=',' read -ra SYMBOLS <<< "$INPUT_SYMBOLS"
            for sym in "${SYMBOLS[@]}"; do
              sym=$(echo "$sym" | xargs)
              if [ -z "$sym" ]; then
                continue
              fi
              python -m src.intraday_forecast_job --horizon 15m --symbol "$sym" --generate-paths
              python -m src.intraday_forecast_job --horizon 1h --symbol "$sym" --generate-paths
            done
          else
            python -m src.intraday_forecast_job --horizon 15m --generate-paths
            python -m src.intraday_forecast_job --horizon 1h --generate-paths
          fi

      - name: Trigger chart cache refresh
        if: steps.fetch.outputs.total_bars != '0'
        continue-on-error: true
        run: |
          # Optional: Notify the iOS app or invalidate caches
          echo "Data updated, clients should see fresh data on next fetch"

          # Could add webhook notification here if needed
          # curl -X POST "$WEBHOOK_URL" -d '{"event": "intraday_updated"}'

      - name: Report results
        if: always()
        run: |
          echo "## Summary"
          echo "- Market State: ${{ needs.check-market.outputs.market_state }}"
          echo "- Total Bars: ${{ steps.fetch.outputs.total_bars }}"
          echo "- Failed Timeframes: ${{ steps.fetch.outputs.failed_timeframes || 'None' }}"
