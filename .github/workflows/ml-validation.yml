name: ML Validation - Comprehensive Tests

# Comprehensive ML testing: unit tests, coverage, integration tests
# Runs on schedule, manual trigger, or when dependencies change
on:
  # Weekly testing (Monday 2:00 UTC = Sunday 21:00 EST)
  schedule:
    - cron: '0 2 * * 1'
  # Manual trigger via workflow_dispatch
  workflow_dispatch:
    inputs:
      python-version:
        description: 'Python version(s) to test'
        required: false
        default: '3.10,3.11'
        type: string
  # Run on requirement changes (heavy dependency updates)
  push:
    branches: [ master, main, develop ]
    paths:
      - 'ml/requirements*.txt'
      - '.github/workflows/ml-validation.yml'
  pull_request:
    branches: [ master, main, develop ]
    paths:
      - 'ml/requirements*.txt'

# Cancel in-progress runs for same ref
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  # ===========================================================================
  # COMPREHENSIVE ML TESTS (Full test suite with coverage)
  # ===========================================================================
  test-ml:
    name: ML Tests (Python ${{ matrix.python-version }})
    runs-on: ubuntu-latest

    strategy:
      fail-fast: false
      matrix:
        python-version: ['3.10', '3.11']

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python-version }}
        cache: 'pip'
        cache-dependency-path: ml/requirements*.txt

    - name: Cache Python packages
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ matrix.python-version }}-${{ hashFiles('ml/requirements*.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-${{ matrix.python-version }}-
          ${{ runner.os }}-pip-

    - name: Install ML dependencies
      run: |
        cd ml
        python -m pip install --upgrade pip
        pip install -r requirements.txt

        # Install dev dependencies
        if [ -f requirements-dev.txt ]; then
          pip install -r requirements-dev.txt
        else
          # Install common test tools if requirements-dev.txt doesn't exist
          pip install pytest pytest-cov pytest-asyncio diff-cover
        fi

    - name: Run unit tests with coverage
      run: |
        cd ml
        pytest tests/ \
          --cov=src \
          --cov-report=xml \
          --cov-report=term-missing \
          --cov-report=html \
          -v \
          --tb=short \
          --maxfail=5

    - name: Enforce diff coverage (>=90%)
      continue-on-error: true
      run: |
        cd ml
        if [ -f coverage.xml ]; then
          diff-cover coverage.xml \
            --compare-branch origin/${{ github.base_ref || 'master' }} \
            --fail-under 90 || echo "‚ö†Ô∏è Diff coverage below threshold"
        fi

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v4
      with:
        file: ./ml/coverage.xml
        flags: ml-tests-py${{ matrix.python-version }}
        name: ml-coverage-py${{ matrix.python-version }}
        fail_ci_if_error: false
      env:
        CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}

    - name: Upload HTML coverage report
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: ml-coverage-html-py${{ matrix.python-version }}
        path: ml/htmlcov/
        retention-days: 7

  # ===========================================================================
  # ML CODE QUALITY (Full analysis with security)
  # ===========================================================================
  lint-ml-comprehensive:
    name: ML Code Quality & Security
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python 3.10
      uses: actions/setup-python@v5
      with:
        python-version: '3.10'
        cache: 'pip'
        cache-dependency-path: ml/requirements*.txt

    - name: Cache Python packages
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-lint-${{ hashFiles('ml/requirements*.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-lint-

    - name: Install dependencies
      run: |
        cd ml
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install black mypy flake8 isort bandit safety pytest

    - name: Check formatting (Black)
      run: |
        cd ml
        black --check src tests || (
          echo "‚ùå Code formatting issues detected"
          echo "Run: black src tests"
          exit 1
        )

    - name: Check import sorting (isort)
      run: |
        cd ml
        isort --check-only src tests || (
          echo "‚ùå Import sorting issues detected"
          echo "Run: isort src tests"
          exit 1
        )

    - name: Lint (flake8)
      run: |
        cd ml
        flake8 src tests \
          --max-line-length=120 \
          --extend-ignore=E203,W503 \
          --statistics

    - name: Type check (mypy)
      continue-on-error: true
      run: |
        cd ml
        mypy src --ignore-missing-imports --pretty

    - name: Security check (Bandit)
      continue-on-error: true
      run: |
        cd ml
        bandit -r src -f json -o bandit-report.json
        bandit -r src -f screen

    - name: Dependency vulnerabilities (Safety)
      continue-on-error: true
      run: |
        cd ml
        safety check --json || echo "‚ö†Ô∏è Some vulnerabilities detected"

    - name: Upload Bandit report
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: bandit-report
        path: ml/bandit-report.json
        retention-days: 7

  # ===========================================================================
  # ML INTEGRATION TESTS (Test ML pipeline components)
  # ===========================================================================
  integration-tests:
    name: ML Integration Tests
    runs-on: ubuntu-latest
    if: github.event_name != 'schedule'  # Skip on schedule to save time

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python 3.10
      uses: actions/setup-python@v5
      with:
        python-version: '3.10'
        cache: 'pip'
        cache-dependency-path: ml/requirements*.txt

    - name: Cache Python packages
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-integration-${{ hashFiles('ml/requirements*.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-integration-

    - name: Install dependencies
      run: |
        cd ml
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        if [ -f requirements-dev.txt ]; then
          pip install -r requirements-dev.txt
        else
          pip install pytest pytest-asyncio
        fi

    - name: Run integration tests
      continue-on-error: true
      run: |
        cd ml
        # Run tests tagged as integration
        pytest tests/ -m integration -v --tb=short || echo "‚ö†Ô∏è Integration tests completed with warnings"

  # ===========================================================================
  # COMPREHENSIVE SUMMARY
  # ===========================================================================
  ml-validation-summary:
    name: ML Validation Summary
    runs-on: ubuntu-latest
    needs: [test-ml, lint-ml-comprehensive, integration-tests]
    if: always()

    steps:
    - name: Generate comprehensive report
      run: |
        echo "# üî¨ ML Validation Report" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Event**: ${{ github.event_name }}" >> $GITHUB_STEP_SUMMARY
        echo "**Branch**: \`${{ github.ref_name }}\`" >> $GITHUB_STEP_SUMMARY
        echo "**Commit**: \`${{ github.sha }}\`" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY

        echo "## üìä Test Results" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY

        # Unit Tests
        echo "### Unit Tests (Python 3.10 & 3.11)" >> $GITHUB_STEP_SUMMARY
        if [ "${{ needs.test-ml.result }}" = "success" ]; then
          echo "‚úÖ **PASSED** - All unit tests passed with coverage" >> $GITHUB_STEP_SUMMARY
        elif [ "${{ needs.test-ml.result }}" = "failure" ]; then
          echo "‚ùå **FAILED** - Unit tests failed. Check logs for details." >> $GITHUB_STEP_SUMMARY
        else
          echo "‚è≠Ô∏è SKIPPED" >> $GITHUB_STEP_SUMMARY
        fi
        echo "" >> $GITHUB_STEP_SUMMARY

        # Code Quality
        echo "### Code Quality & Security" >> $GITHUB_STEP_SUMMARY
        if [ "${{ needs.lint-ml-comprehensive.result }}" = "success" ]; then
          echo "‚úÖ **PASSED** - Formatting, linting, types, and security checks passed" >> $GITHUB_STEP_SUMMARY
        elif [ "${{ needs.lint-ml-comprehensive.result }}" = "failure" ]; then
          echo "‚ùå **FAILED** - Code quality checks failed. Check logs for details." >> $GITHUB_STEP_SUMMARY
        else
          echo "‚è≠Ô∏è SKIPPED" >> $GITHUB_STEP_SUMMARY
        fi
        echo "" >> $GITHUB_STEP_SUMMARY

        # Integration Tests
        echo "### Integration Tests" >> $GITHUB_STEP_SUMMARY
        if [ "${{ needs.integration-tests.result }}" = "success" ]; then
          echo "‚úÖ **PASSED** - Integration tests passed" >> $GITHUB_STEP_SUMMARY
        elif [ "${{ needs.integration-tests.result }}" = "failure" ]; then
          echo "‚ö†Ô∏è **COMPLETED WITH WARNINGS** - Integration tests had issues" >> $GITHUB_STEP_SUMMARY
        else
          echo "‚è≠Ô∏è SKIPPED (schedule runs only)" >> $GITHUB_STEP_SUMMARY
        fi
        echo "" >> $GITHUB_STEP_SUMMARY

        echo "## üîç Coverage Artifacts" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "- HTML Coverage Reports (see Actions artifacts)" >> $GITHUB_STEP_SUMMARY
        echo "- Codecov Integration: [codecov.io](https://codecov.io)" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY

        echo "## üìÖ Execution Schedule" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "| Trigger | Frequency | Python Versions |" >> $GITHUB_STEP_SUMMARY
        echo "|---------|-----------|-----------------|" >> $GITHUB_STEP_SUMMARY
        echo "| Schedule | Weekly (Monday 2:00 UTC) | 3.10, 3.11 |" >> $GITHUB_STEP_SUMMARY
        echo "| requirements.txt changes | On push/PR | 3.10, 3.11 |" >> $GITHUB_STEP_SUMMARY
        echo "| Manual trigger | On-demand | User-selected |" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "---" >> $GITHUB_STEP_SUMMARY
        echo "_Generated by GitHub Actions_" >> $GITHUB_STEP_SUMMARY

    - name: Check overall status
      run: |
        if [ "${{ needs.test-ml.result }}" = "failure" ] || \
           [ "${{ needs.lint-ml-comprehensive.result }}" = "failure" ]; then
          echo "‚ùå ML validation failed"
          exit 1
        fi

        echo "‚úÖ ML validation completed successfully"
