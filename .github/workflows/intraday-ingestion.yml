name: Intraday Ingestion

# =============================================================================
# CONSOLIDATED INTRADAY DATA INGESTION
# =============================================================================
# Fetches fresh intraday OHLC data during market hours.
# This is the primary source for real-time chart data in the iOS app.
#
# Replaces:
#   - alpaca-intraday-cron.yml (now triggers this workflow)
#   - intraday-update.yml (deprecated)
#   - intraday-update-v2.yml (deprecated, Tradier)
#
# Data Flow:
#   Intraday Ingestion only (forecasting runs separately)
# =============================================================================

on:
  schedule:
    # Run every 15 minutes during extended market hours (9:00 AM - 5:00 PM ET)
    # Cron is in UTC: ET is UTC-5 (winter) or UTC-4 (DST)
    - cron: '*/15 13-22 * * 1-5'  # Every 15 min, 1PM-10PM UTC, Mon-Fri
  workflow_dispatch:
    inputs:
      symbols:
        description: 'Comma-separated symbols (leave empty for all watchlist)'
        required: false
        type: string
      timeframes:
        description: 'Comma-separated timeframes'
        required: false
        type: string
        default: 'm15,h1'
      force_refresh:
        description: 'Force refresh even if data exists'
        required: false
        type: boolean
        default: false

concurrency:
  group: intraday-ingestion-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: read

env:
  SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
  SUPABASE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
  ALPACA_API_KEY: ${{ secrets.ALPACA_API_KEY }}
  ALPACA_API_SECRET: ${{ secrets.ALPACA_API_SECRET }}

jobs:
  check-market:
    runs-on: ubuntu-latest
    outputs:
      should_run: ${{ steps.market.outputs.should_run }}
      market_state: ${{ steps.market.outputs.market_state }}
    steps:
      - name: Check Market Hours
        id: market
        run: |
          # Manual dispatch bypasses market hour checks
          if [ "${GITHUB_EVENT_NAME}" = "workflow_dispatch" ]; then
            echo "Manual dispatch - bypassing market-hour gating"
            echo "should_run=true" >> $GITHUB_OUTPUT
            echo "market_state=manual" >> $GITHUB_OUTPUT
            exit 0
          fi

          # Get current time in ET
          current_hour=$(TZ="America/New_York" date +%H)
          current_min=$(TZ="America/New_York" date +%M)
          day_of_week=$(TZ="America/New_York" date +%u)

          echo "Current ET time: $current_hour:$current_min (day $day_of_week)"

          # Skip weekends
          if [ "$day_of_week" -gt 5 ]; then
            echo "Weekend - skipping"
            echo "should_run=false" >> $GITHUB_OUTPUT
            echo "market_state=weekend" >> $GITHUB_OUTPUT
            exit 0
          fi

          # Check if within extended market hours (9:00 AM - 5:00 PM ET)
          current_minutes=$((current_hour * 60 + current_min))
          pre_market=$((9 * 60))
          post_market=$((17 * 60))
          market_open=$((9 * 60 + 30))
          market_close=$((16 * 60))

          if [ "$current_minutes" -lt "$pre_market" ] || [ "$current_minutes" -gt "$post_market" ]; then
            echo "Outside extended market hours - skipping"
            echo "should_run=false" >> $GITHUB_OUTPUT
            echo "market_state=closed" >> $GITHUB_OUTPUT
            exit 0
          fi

          # Determine market state
          if [ "$current_minutes" -ge "$market_open" ] && [ "$current_minutes" -le "$market_close" ]; then
            echo "market_state=open" >> $GITHUB_OUTPUT
          elif [ "$current_minutes" -lt "$market_open" ]; then
            echo "market_state=pre_market" >> $GITHUB_OUTPUT
          else
            echo "market_state=after_hours" >> $GITHUB_OUTPUT
          fi

          echo "should_run=true" >> $GITHUB_OUTPUT

  ingest-data:
    needs: check-market
    if: needs.check-market.outputs.should_run == 'true'
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup ML Environment
        uses: ./.github/actions/setup-ml-env
        with:
          supabase-url: ${{ secrets.SUPABASE_URL }}
          supabase-key: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          database-url: ${{ secrets.DATABASE_URL }}
          alpaca-api-key: ${{ secrets.ALPACA_API_KEY }}
          alpaca-api-secret: ${{ secrets.ALPACA_API_SECRET }}

      - name: Resolve processing universe
        env:
          INPUT_SYMBOLS: ${{ inputs.symbols }}
          INPUT_TIMEFRAMES: ${{ inputs.timeframes || 'm15,h1' }}
        run: |
          cd ml
          python -m src.scripts.resolve_universe --output env >> $GITHUB_ENV

      - name: Fetch intraday data
        id: fetch
        env:
          INPUT_TIMEFRAMES: ${{ inputs.timeframes || 'm15,h1' }}
          INPUT_SYMBOLS: ${{ inputs.symbols }}
          FORCE_REFRESH: ${{ inputs.force_refresh }}
        run: |
          cd ml
          
          SYMBOL_LIST=${SWIFTBOLT_SYMBOLS:-$INPUT_SYMBOLS}
          SYMBOL_FLAG="--all"
          if [ -n "$SYMBOL_LIST" ]; then
            SYMBOL_FLAG="--symbols $SYMBOL_LIST"
          fi
          
          FORCE_FLAG=""
          if [ "$FORCE_REFRESH" = "true" ]; then
            FORCE_FLAG="--force"
          fi
          
          total_bars=0
          failed_timeframes=""
          skipped_timeframes=""
          
          # Parse and iterate over timeframes
          TIMEFRAME_CSV=${SWIFTBOLT_TIMEFRAMES:-$INPUT_TIMEFRAMES}
          IFS=',' read -ra TIMEFRAMES <<< "$TIMEFRAME_CSV"
          for tf in "${TIMEFRAMES[@]}"; do
            tf=$(echo "$tf" | xargs)  # Trim whitespace
            [ -z "$tf" ] && continue
            
            echo "üìä Fetching $tf data..."
            
            # Capture full output and exit code
            set +e
            output=$(python src/scripts/alpaca_backfill_ohlc_v2.py $SYMBOL_FLAG --timeframe $tf $FORCE_FLAG 2>&1)
            exit_code=$?
            set -e
            
            # Show last 30 lines of output
            echo "$output" | tail -n 30
            
            # Check for actual errors vs skips
            if [ $exit_code -eq 0 ]; then
              # Success - check if bars were inserted or skipped
              bars=$(echo "$output" | grep -oP 'Inserted \K\d+' | tail -1 || echo "0")
              bars=${bars:-0}
              
              # Check if all symbols were skipped
              skipped_count=$(echo "$output" | grep -c "‚è≠Ô∏è  Skipping" || echo "0")
              if [ "$bars" -eq 0 ] && [ "$skipped_count" -gt 0 ]; then
                echo "‚ÑπÔ∏è  $tf: All symbols skipped (market closed or data fresh)"
                skipped_timeframes="$skipped_timeframes $tf"
              else
                total_bars=$((total_bars + bars))
                echo "‚úÖ $tf: $bars bars inserted"
              fi
            else
              # Actual failure - log error details
              echo "‚ùå $tf failed with exit code $exit_code"
              echo "::warning::Timeframe $tf failed. Check logs above for details."
              failed_timeframes="$failed_timeframes $tf"
              
              # Show error details
              echo "$output" | grep -i "error\|failed\|exception" | head -10 || true
            fi
          done
          
          echo "total_bars=$total_bars" >> $GITHUB_OUTPUT
          
          # Determine status
          if [ -n "$failed_timeframes" ]; then
            echo "status=partial" >> $GITHUB_OUTPUT
            echo "::warning::Some timeframes failed:$failed_timeframes"
          elif [ -n "$skipped_timeframes" ] && [ "$total_bars" -eq 0 ]; then
            echo "status=skipped" >> $GITHUB_OUTPUT
            echo "‚ÑπÔ∏è  All timeframes skipped (market closed or data fresh)"
          else
            echo "status=success" >> $GITHUB_OUTPUT
          fi

      - name: Validate OHLC integrity
        continue-on-error: true
        run: |
          cd ml
          python -c "
          import os
          from dotenv import load_dotenv
          load_dotenv()
          
          from src.data.data_validator import OHLCValidator
          from src.data.supabase_db import db
          from src.scripts.universe_utils import get_symbol_universe

          validator = OHLCValidator()
          universe = get_symbol_universe()
          symbols = universe.get('symbols', []) or ['SPY', 'AAPL']
          timeframes = universe.get('timeframes', []) or ['m15', 'h1']
          
          validation_errors = []
          validation_warnings = []
          
          # Sample validation on top 3 symbols
          for sym in symbols[:3]:
            sym = sym.strip()
            if not sym:
              continue
            for tf in timeframes[:2]:
              try:
                df = db.fetch_ohlc_bars(sym, timeframe=tf, limit=100)
                if df.empty:
                  print(f'‚ö†Ô∏è {sym}/{tf}: No data found')
                  validation_warnings.append(f'{sym}/{tf}: No data')
                  continue
                
                df, result = validator.validate(df, fix_issues=False)
                if not result.is_valid:
                  # Distinguish critical errors from warnings
                  issues = result.issues or []
                  critical_issues = [i for i in issues if any(crit in i.lower() for crit in ['high <', 'negative volume', 'non-positive'])]
                  warning_issues = [i for i in issues if i not in critical_issues]
                  
                  if critical_issues:
                    error_msg = f'{sym}/{tf}: {critical_issues}'
                    validation_errors.append(error_msg)
                    print(f'‚ùå {error_msg}')
                  # Only log warnings if there are multiple or they're significant
                  # Single outliers/gaps are common in market data and don't need reporting
                  if warning_issues and len(warning_issues) > 1:
                    warning_msg = f'{sym}/{tf}: {warning_issues}'
                    validation_warnings.append(warning_msg)
                    print(f'‚ö†Ô∏è {warning_msg}')
                  elif warning_issues:
                    # Single warning - log at debug level only
                    pass
                else:
                  print(f'‚úÖ {sym}/{tf}: Valid ({len(df)} bars, latest: {df.ts.max()})')
              except Exception as e:
                print(f'‚ö†Ô∏è {sym}/{tf}: Validation error - {e}')
                validation_warnings.append(f'{sym}/{tf}: {str(e)}')
          
          # Report results
          if validation_errors:
            print('')
            print('‚ùå Critical OHLC validation errors (should be reviewed):')
            for error in validation_errors:
              print(f'  - {error}')
            print('')
            print('::warning::Critical OHLC data quality issues detected. Review data quality.')
          elif validation_warnings:
            print('')
            print('‚ö†Ô∏è OHLC validation warnings (non-critical, common in market data):')
            for warning in validation_warnings:
              print(f'  - {warning}')
            print('')
            print('Note: Single outliers or gaps are normal in market data and can be ignored.')
            # Don't create GitHub warning for minor validation issues
            # Only log them for visibility
          else:
            print('')
            print('‚úÖ OHLC integrity validated for all checked symbols/timeframes')
          "

      - name: Job summary
        if: always()
        run: |
          echo "## Intraday Ingestion" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Status**: ${{ steps.fetch.outputs.status }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Market State**: ${{ needs.check-market.outputs.market_state }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Total Bars Updated**: ${{ steps.fetch.outputs.total_bars }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Timeframes**: ${{ inputs.timeframes || 'm15,h1' }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Notes" >> $GITHUB_STEP_SUMMARY
          echo "- Status 'skipped' means market is closed or data is fresh (expected)" >> $GITHUB_STEP_SUMMARY
          echo "- Status 'partial' means some timeframes failed (check logs)" >> $GITHUB_STEP_SUMMARY
          echo "- OHLC validation warnings are non-blocking" >> $GITHUB_STEP_SUMMARY

  push-metrics:
    needs: [check-market, ingest-data]
    if: always() && needs.ingest-data.result == 'success'
    runs-on: ubuntu-latest
    
    steps:
      - name: Report success metrics
        run: |
          echo "## Intraday Ingestion Complete" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Market State**: ${{ needs.check-market.outputs.market_state }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Trigger**: ${{ github.event_name }}" >> $GITHUB_STEP_SUMMARY

  # =============================================================================
  # UNDERLYING HISTORY REFRESH (After Hours)
  # =============================================================================
  # Refreshes 7-day underlying metrics for options ranking
  # Only runs during after-hours (4-5 PM ET) or manual dispatch
  refresh-underlying-history:
    needs: [check-market, ingest-data]
    if: |
      always() &&
      needs.ingest-data.result == 'success' &&
      (needs.check-market.outputs.market_state == 'after_hours' ||
       needs.check-market.outputs.market_state == 'manual')
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup ML Environment
        uses: ./.github/actions/setup-ml-env
        with:
          supabase-url: ${{ secrets.SUPABASE_URL }}
          supabase-key: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          database-url: ${{ secrets.DATABASE_URL }}
          alpaca-api-key: ${{ secrets.ALPACA_API_KEY }}
          alpaca-api-secret: ${{ secrets.ALPACA_API_SECRET }}

      - name: Refresh underlying history
        id: refresh
        run: |
          cd ml
          echo "üìä Refreshing 7-day underlying history for watchlist symbols..."

          # Capture output and exit code separately
          set +e
          output=$(python -m src.scripts.refresh_underlying_history --watchlist --timeframe d1 2>&1)
          exit_code=$?
          set -e

          # Always print the output for debugging
          echo "$output"

          if [ $exit_code -eq 0 ]; then
            successful=$(echo "$output" | grep -oP 'Successful: \K\d+' || echo "0")
            failed=$(echo "$output" | grep -oP 'Failed: \K\d+' || echo "0")
            bars=$(echo "$output" | grep -oP 'Total bars upserted: \K\d+' || echo "0")

            echo "successful=$successful" >> $GITHUB_OUTPUT
            echo "failed=$failed" >> $GITHUB_OUTPUT
            echo "bars=$bars" >> $GITHUB_OUTPUT

            if [ "$failed" -gt 0 ]; then
              echo "status=partial" >> $GITHUB_OUTPUT
              echo "::warning::Some symbols failed to refresh"
            else
              echo "status=success" >> $GITHUB_OUTPUT
            fi
          else
            echo "status=failed" >> $GITHUB_OUTPUT
            echo "::error::Underlying history refresh failed with exit code $exit_code"
            # Log to summary for visibility
            echo "## ‚ùå Underlying History Refresh Failed" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            echo "$output" | tail -50 >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            exit 1
          fi

      - name: Job summary
        if: always()
        run: |
          echo "## Underlying History Refresh" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Status**: ${{ steps.refresh.outputs.status || 'unknown' }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Successful**: ${{ steps.refresh.outputs.successful || '0' }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Failed**: ${{ steps.refresh.outputs.failed || '0' }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Total Bars**: ${{ steps.refresh.outputs.bars || '0' }}" >> $GITHUB_STEP_SUMMARY
