name: Intraday Ingestion

# =============================================================================
# CONSOLIDATED INTRADAY DATA INGESTION
# =============================================================================
# Fetches fresh intraday OHLC data during market hours.
# This is the primary source for real-time chart data in the iOS app.
#
# Replaces:
#   - alpaca-intraday-cron.yml (now triggers this workflow)
#   - intraday-update.yml (deprecated)
#   - intraday-update-v2.yml (deprecated, Tradier)
#
# Data Flow:
#   Intraday Ingestion â†’ Intraday Forecast (workflow_run trigger)
# =============================================================================

on:
  schedule:
    # Run every 15 minutes during extended market hours (9:00 AM - 5:00 PM ET)
    # Cron is in UTC: ET is UTC-5 (winter) or UTC-4 (DST)
    - cron: '*/15 13-22 * * 1-5'  # Every 15 min, 1PM-10PM UTC, Mon-Fri
  workflow_dispatch:
    inputs:
      symbols:
        description: 'Comma-separated symbols (leave empty for all watchlist)'
        required: false
        type: string
      timeframes:
        description: 'Comma-separated timeframes'
        required: false
        type: string
        default: 'm15,h1'
      force_refresh:
        description: 'Force refresh even if data exists'
        required: false
        type: boolean
        default: false

concurrency:
  group: intraday-ingestion-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: read

env:
  SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
  SUPABASE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
  ALPACA_API_KEY: ${{ secrets.ALPACA_API_KEY }}
  ALPACA_API_SECRET: ${{ secrets.ALPACA_API_SECRET }}

jobs:
  check-market:
    runs-on: ubuntu-latest
    outputs:
      should_run: ${{ steps.market.outputs.should_run }}
      market_state: ${{ steps.market.outputs.market_state }}
    steps:
      - name: Check Market Hours
        id: market
        run: |
          # Manual dispatch bypasses market hour checks
          if [ "${GITHUB_EVENT_NAME}" = "workflow_dispatch" ]; then
            echo "Manual dispatch - bypassing market-hour gating"
            echo "should_run=true" >> $GITHUB_OUTPUT
            echo "market_state=manual" >> $GITHUB_OUTPUT
            exit 0
          fi

          # Get current time in ET
          current_hour=$(TZ="America/New_York" date +%H)
          current_min=$(TZ="America/New_York" date +%M)
          day_of_week=$(TZ="America/New_York" date +%u)

          echo "Current ET time: $current_hour:$current_min (day $day_of_week)"

          # Skip weekends
          if [ "$day_of_week" -gt 5 ]; then
            echo "Weekend - skipping"
            echo "should_run=false" >> $GITHUB_OUTPUT
            echo "market_state=weekend" >> $GITHUB_OUTPUT
            exit 0
          fi

          # Check if within extended market hours (9:00 AM - 5:00 PM ET)
          current_minutes=$((current_hour * 60 + current_min))
          pre_market=$((9 * 60))
          post_market=$((17 * 60))
          market_open=$((9 * 60 + 30))
          market_close=$((16 * 60))

          if [ "$current_minutes" -lt "$pre_market" ] || [ "$current_minutes" -gt "$post_market" ]; then
            echo "Outside extended market hours - skipping"
            echo "should_run=false" >> $GITHUB_OUTPUT
            echo "market_state=closed" >> $GITHUB_OUTPUT
            exit 0
          fi

          # Determine market state
          if [ "$current_minutes" -ge "$market_open" ] && [ "$current_minutes" -le "$market_close" ]; then
            echo "market_state=open" >> $GITHUB_OUTPUT
          elif [ "$current_minutes" -lt "$market_open" ]; then
            echo "market_state=pre_market" >> $GITHUB_OUTPUT
          else
            echo "market_state=after_hours" >> $GITHUB_OUTPUT
          fi

          echo "should_run=true" >> $GITHUB_OUTPUT

  ingest-data:
    needs: check-market
    if: needs.check-market.outputs.should_run == 'true'
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup ML Environment
        uses: ./.github/actions/setup-ml-env
        with:
          supabase-url: ${{ secrets.SUPABASE_URL }}
          supabase-key: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          database-url: ${{ secrets.DATABASE_URL }}
          alpaca-api-key: ${{ secrets.ALPACA_API_KEY }}
          alpaca-api-secret: ${{ secrets.ALPACA_API_SECRET }}

      - name: Resolve processing universe
        env:
          INPUT_SYMBOLS: ${{ inputs.symbols }}
          INPUT_TIMEFRAMES: ${{ inputs.timeframes || 'm15,h1' }}
        run: |
          cd ml
          python -m src.scripts.resolve_universe --output env >> $GITHUB_ENV

      - name: Fetch intraday data
        id: fetch
        env:
          INPUT_TIMEFRAMES: ${{ inputs.timeframes || 'm15,h1' }}
          INPUT_SYMBOLS: ${{ inputs.symbols }}
          FORCE_REFRESH: ${{ inputs.force_refresh }}
        run: |
          cd ml
          
          SYMBOL_LIST=${SWIFTBOLT_SYMBOLS:-$INPUT_SYMBOLS}
          SYMBOL_FLAG="--all"
          if [ -n "$SYMBOL_LIST" ]; then
            SYMBOL_FLAG="--symbols $SYMBOL_LIST"
          fi
          
          FORCE_FLAG=""
          if [ "$FORCE_REFRESH" = "true" ]; then
            FORCE_FLAG="--force"
          fi
          
          total_bars=0
          failed_timeframes=""
          
          # Parse and iterate over timeframes
          TIMEFRAME_CSV=${SWIFTBOLT_TIMEFRAMES:-$INPUT_TIMEFRAMES}
          IFS=',' read -ra TIMEFRAMES <<< "$TIMEFRAME_CSV"
          for tf in "${TIMEFRAMES[@]}"; do
            tf=$(echo "$tf" | xargs)  # Trim whitespace
            [ -z "$tf" ] && continue
            
            echo "ðŸ“Š Fetching $tf data..."
            
            if output=$(python src/scripts/alpaca_backfill_ohlc_v2.py $SYMBOL_FLAG --timeframe $tf $FORCE_FLAG 2>&1); then
              echo "$output" | tail -n 30
              bars=$(echo "$output" | grep -oP 'Inserted \K\d+' | tail -1 || echo "0")
              bars=${bars:-0}
              total_bars=$((total_bars + bars))
              echo "âœ… $tf: $bars bars"
            else
              echo "âŒ $tf failed"
              failed_timeframes="$failed_timeframes $tf"
            fi
          done
          
          echo "total_bars=$total_bars" >> $GITHUB_OUTPUT
          
          if [ -n "$failed_timeframes" ]; then
            echo "status=partial" >> $GITHUB_OUTPUT
            echo "::warning::Some timeframes failed:$failed_timeframes"
          else
            echo "status=success" >> $GITHUB_OUTPUT
          fi

      - name: Quick validation
        run: |
          cd ml
          python -c "
          import os
          from dotenv import load_dotenv
          load_dotenv()
          
          from src.data.supabase_db import db
          from src.scripts.universe_utils import get_symbol_universe

          universe = get_symbol_universe()
          symbols = universe.get('symbols', []) or ['SPY', 'AAPL']
          timeframes = universe.get('timeframes', []) or ['m15', 'h1']
          
          for sym in symbols[:3]:
            sym = sym.strip()
            if not sym:
              continue
            for tf in timeframes[:2]:
              df = db.fetch_ohlc_bars(sym, timeframe=tf, limit=5)
              if not df.empty:
                print(f'âœ… {sym}/{tf}: {len(df)} bars, latest: {df.ts.max()}')
              else:
                print(f'âš ï¸ {sym}/{tf}: No data')
          "

      - name: Job summary
        if: always()
        run: |
          echo "## Intraday Ingestion" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Status**: ${{ steps.fetch.outputs.status }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Market State**: ${{ needs.check-market.outputs.market_state }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Total Bars Updated**: ${{ steps.fetch.outputs.total_bars }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Timeframes**: ${{ inputs.timeframes || 'm15,h1' }}" >> $GITHUB_STEP_SUMMARY

  push-metrics:
    needs: [check-market, ingest-data]
    if: always() && needs.ingest-data.result == 'success'
    runs-on: ubuntu-latest
    
    steps:
      - name: Report success metrics
        run: |
          echo "## Intraday Ingestion Complete" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Market State**: ${{ needs.check-market.outputs.market_state }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Trigger**: ${{ github.event_name }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Next Steps" >> $GITHUB_STEP_SUMMARY
          echo "- Intraday Forecast workflow will trigger automatically" >> $GITHUB_STEP_SUMMARY
          echo "- Check \`intraday-forecast.yml\` for forecast generation" >> $GITHUB_STEP_SUMMARY

  # =============================================================================
  # UNDERLYING HISTORY REFRESH (After Hours)
  # =============================================================================
  # Refreshes 7-day underlying metrics for options ranking
  # Only runs during after-hours (4-5 PM ET) or manual dispatch
  refresh-underlying-history:
    needs: [check-market, ingest-data]
    if: |
      always() &&
      needs.ingest-data.result == 'success' &&
      (needs.check-market.outputs.market_state == 'after_hours' ||
       needs.check-market.outputs.market_state == 'manual')
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup ML Environment
        uses: ./.github/actions/setup-ml-env
        with:
          supabase-url: ${{ secrets.SUPABASE_URL }}
          supabase-key: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          database-url: ${{ secrets.DATABASE_URL }}
          alpaca-api-key: ${{ secrets.ALPACA_API_KEY }}
          alpaca-api-secret: ${{ secrets.ALPACA_API_SECRET }}

      - name: Refresh underlying history
        id: refresh
        run: |
          cd ml
          echo "ðŸ“Š Refreshing 7-day underlying history for watchlist symbols..."

          # Capture output and exit code separately
          set +e
          output=$(python -m src.scripts.refresh_underlying_history --watchlist --timeframe d1 2>&1)
          exit_code=$?
          set -e

          # Always print the output for debugging
          echo "$output"

          if [ $exit_code -eq 0 ]; then
            successful=$(echo "$output" | grep -oP 'Successful: \K\d+' || echo "0")
            failed=$(echo "$output" | grep -oP 'Failed: \K\d+' || echo "0")
            bars=$(echo "$output" | grep -oP 'Total bars upserted: \K\d+' || echo "0")

            echo "successful=$successful" >> $GITHUB_OUTPUT
            echo "failed=$failed" >> $GITHUB_OUTPUT
            echo "bars=$bars" >> $GITHUB_OUTPUT

            if [ "$failed" -gt 0 ]; then
              echo "status=partial" >> $GITHUB_OUTPUT
              echo "::warning::Some symbols failed to refresh"
            else
              echo "status=success" >> $GITHUB_OUTPUT
            fi
          else
            echo "status=failed" >> $GITHUB_OUTPUT
            echo "::error::Underlying history refresh failed with exit code $exit_code"
            # Log to summary for visibility
            echo "## âŒ Underlying History Refresh Failed" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            echo "$output" | tail -50 >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            exit 1
          fi

      - name: Job summary
        if: always()
        run: |
          echo "## Underlying History Refresh" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Status**: ${{ steps.refresh.outputs.status || 'unknown' }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Successful**: ${{ steps.refresh.outputs.successful || '0' }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Failed**: ${{ steps.refresh.outputs.failed || '0' }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Total Bars**: ${{ steps.refresh.outputs.bars || '0' }}" >> $GITHUB_STEP_SUMMARY
